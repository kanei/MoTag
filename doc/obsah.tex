%=========================================================================
% (c) Michal Bidlo, Bohuslav Køena, 2008

\chapter{Úvod}
Tato práce pojednává o vyu¾ití existujících øe¹ení, vyu¾ívajících algoritmù automatického poèítaèového uèení (Conditional Random Fields s vyu¾ítím algoritmù Limited-memory BFGS a Stochastic Gradient Descent) a porovnání výsledkù s existujícími øe¹eními, kterými v na¹em pøípadì je program Morèe vyvíjený na pra¾ské Univerzitì Karlovì, pou¾ívající Hidden Markov Model. Z existujících øe¹ení poté byly vybrány programy CRF++ a CrfSuite.

V dokumentu bude nejdøíve popsáno samotné znaèkování èe¹tiny a jeho pravidla, a potí¾e, které jsou s ním spojeny v porovnání s jinými, jednodu¹¹ími jazyky. Dále budou rozebrány matematické modely a algoritmy, které jsou pou¾ity pøi procesu uèení. K celému procesu bylo potøeba vytvoøit nìkolik nástrojù, buï konvertujících vstupní data pro jednotlivé programy, nebo ulehèujících vlastní proces testování. Mezi tyto patøí skritpy napsané v jazyce Python a bash a informaèní systém, starající se o správu bì¾ících a dokonèených testù a informací o nich, implementovaný za pomocí PHP, SQL a HTML, postavený na open-source CMS systému Drupal. Ve¹kerý kód byl spravován pomocí verzovacího systému GIT a je veøejnì dostupný na internetu\cite{zdrojak}.

Nejdùle¾itìj¹í èástí dokumentù pak jsou výsledky testování, zpracovávaného na ¹kolních strojích pøes vzdálený pøistup. Testy byly provedeny z mnoha rùzných úhlù pohledu na efektivitu a jsou doplnìny o tabulky a grafy. 

Pro úschovu a verzování zdrojového kódu byl vyu¾it program git a kód je veøejnì pøístupný \cite{zdrojak}.

\section{Termíny}
Pro dal¹í text definujeme následující termíny:
\begin{itemize}
	\item \textbf{Znaèka} -- \textit{angl. Label} -- øetìzec popisující vlastnost
 		daného prvku, v na¹em pøípadì urèení mluvnických tøíd.
	\item \textbf{Rys} -- \textit{angl. Feature} -- prvek pou¾ívaný pøi trénování,
		specifikující vlastnost daného prvku ve vstupních datech.
	\item \textbf{Vlastnost} -- \textit{angl. Atribut} -- pravidlo pro generování
		jednotlivých rysù 
	\item \textbf{Lemma} -- základní podoba slova (slovníkový tvar)
\end{itemize}
\chapter{Znaèkování èeského jazyka}
\section{Proè znaèkovat jazyk}
V èeském jazyce má mnoho slov tzv. homonymní tvar -- jedno slovo mù¾e být v rùzných pøípadech naprosto odli¹ným slovním druhem, nebo mít odli¹né urèení slovních kategorií. Pøi strojové analýze textu, pøekladech apod. je proto dùle¾ité, abychom byli schopni tyto kategorie rozli¹ovat a pøiøazovat jednotlivým slovùm jejich správnou znaèku.
\section{Co je to znaèkování}
Proces, pøi kterém je slovu, pøiøazena  znaèka obsahující jeho popis z mluvnického hlediska. Tento proces je èasto rozdìlen na nìkolik krokù, kdy slovu nejdøíve pøiøadíme v¹echny mo¾né znaèky a poté teprve vybereme tu správnou. V této práci se budeme zabývat pouze druhým krokem a v¹echna vstupní data proto ji¾ budou mít nastavena mno¾inu v¹ech znaèek, pøipadajících v úvahu. 
\section{Kategorie popisované znaèkou v èeském jazyce}
Ka¾dé slovo èeského jazyka má mnoho kategorií, do kterých mù¾e být zaøazeno -- od slovního druhu po slovesný vid. V poèítaèovém zpracování jazyka lze pou¾ít nìkolika rùzných pøístupù k ulo¾ení tìchto informací. V na¹em pøípadì bude struktura znaèek odpovídat systému\cite{znacky} pou¾ívanému na pra¾ské Univerzitì Karlovì. Tento systém se skládá ze 16 pozic viz tabulka ~\ref{tab:PopisZnacek}.
\begin{center}
	\begin{tabular}{|c|l|}
		\hline
		Pozice & Popis \\
		\hline
		1 & Slovní druh \\
		2 & Detail slovního druhu \\
		3 & Jmenný rod \\
		4 & Èíslo \\
		5 & Pád \\
		6 & Pøivlastòovací rod \\
		7 & Pøivlastòovací èíslo \\
		8 & Osoba \\
		9 & Èas \\
		10 & Stupeò \\
		11 & Negace \\
		12 & Aktívum/pasívum \\	
		13 & Nepou¾ito \\
		14 & Nepou¾ito \\
		15 & Varianta, stylový pøíznak a pod. \\
		16 & Slovesný vid \\
		\hline
	\end{tabular}
	\captionof{table}{Popis jednotlivých pozic morfologické znaèky}
	\label{tab:PopisZnacek}
\end{center}

\section{Problémy pøi znaèkování}
Zatímco v angliètinì pøi pouhém oznaèkování slov s jednoznaènou znaèkou dosáhneme úspì¹nosti kolem 90\%, v èeském jazyce je situace mnohem slo¾itìj¹í. Kvùli vý¹e zmínìné homonymii a mno¾ství kategorii, do kterých v èeském jazyce slova mù¾eme zaøadit, bychom se v na¹em pøípadì k 90\% urèitì ani nepøiblí¾ili. V angliètinì se proto také pou¾ívá pouze tøí-pozicová znaèka, která velmi ulehèuje práci ve¹kerým automatickým programùm. Pøi takto nízkém poètu je také velmi nízká pamì»ová nároènost a poèet mo¾ných pøechodù není tak vysoký. Naproti tomu v èe¹tinì je kvùli 16 pozicím mo¾no získat celkový poèet znaèek v øádu tisícù a tím se neúmìrnì zvy¹uje èasová i pamì»ová nároènost celého procesu znaèkování. Z tohoto dùvodu jsem se pokou¹el tuto nároènost sní¾it vypu¹tìním ménì dùle¾itých kategorií a tím sní¾it celkový poèet variant k èíslu nepøevy¹ujícímu jeden tisíc. Nároènost na procesorový èas se tím razantnì sní¾ila a dala mi tak ¹anci otestovat mnohem vìt¹í mno¾ství kombinací rysù a nastavení programù.
\section{Data}
K trénování a následné evaluaci výsledkù máme k dispozici okolo 77 000 vìt. Data jsou získána z korpusu PDT 2.0 a ulo¾ena ve formátu dat CSTS\cite{csts}. Pomocí skriptù napsaných pøevá¾nì v jazyce python jsou poté tato data pøevedena do formátu kompatibilního s pou¾itými programy.
\section{Existující øe¹ení pro znaèkování èeského jazyka}
Pro porovnání výsledkù tohoto projektu byl pou¾it program Morèe\cite{Morce} vytvoøený na Ústavu formální a aplikované lingvistiky na Univerzitì Karlovì v Praze. K trénování je vyu¾íván Skrytý Markovùv Model s pou¾itím Prùmìrovaného perceptronu. Vstupními daty je korpus PDT 2.0 s údaji ve formátu CSTS. Podle dostupných údajù program dosahuje úspì¹nosti od 95 do 96 procent je tudí¾ nejpøesnìj¹ím znaèkovacím programem pro zpracování èeského jazyka. Z dùvodu pou¾ití stejných dat tedy nebude problém porovnat koneènou úspì¹nost námi pou¾ité implementace s úspì¹ností programu Morèe.

\chapter{Pou¾ité algoritmy}
Pro odli¹ení od existujících øe¹ení byl vybrán algoritmus Conditional Random Fields (Podmínìná náhodná pole), roz¹iøující Hidden Markov Model a tím nabízející vý¹¹í úèinnost na vstupních datech. Pro lep¹í pochopení CRF je potøeba nejdøíve porozumìt zpùsobu, jakým pracuje algoritmus HMM. V mnoha existujících øe¹eních se poté pro urèení parametrù pou¾ívají rùzné algoritmy od Viterbi algorithm, pou¾ívaného ji¾ od 60. let minulého století, pøes Forward-Backward algorithm, jeho modifikaci Baum-Welch algorithm a¾ po \uv{nejmodernìj¹í} zástupce, kterými jsou Low Memory BFGS a Stochastic Gradient Descent, poskytující nejlep¹í výsledky, nebo vysoké sní¾ení pamì»ové a èasové nároènosti.

Celý proces poté probíhá za tzv. Supervised Learning (uèení se pod dohledem), kdy programu nejdøíve pøedlo¾íme ji¾ správnì oznaèená data a necháme jej, aby se pomocí jednoho z vý¹e zmínìných algoritmù nauèil správné parametry modelu (CRF nebo HMM). Takto získaný model poté aplikujeme na men¹í skupinu dat, pomocí které poté urèíme koneènou úspì¹nost celého procesu.

\section{Hiden Markov Model (HMM)}
Skrytý Markovský model (viz.\cite{Kovar}), pojmenovaný po ruském matematikovi Andreyi Markovi, oznaèuje statistický model urèený pro popis posloupnosti obsahující Markovské stavy. Tìmi máme na mysli takový stav, pro nì¾ je dùle¾itá pouze blízká minulost (v na¹em pøípadì pouze nìkolik pøedchozích stavù -- znaèek) a vzdálená minulost je zanedbána. Ve zpracování jazyka se èasto omezuje zpracování pouze na dvì pøedchozí znaèky.

Zatímco u klasického Markovského modelu známe posloupnost vstupních hodnot, v na¹em pøípadì známe pouze posloupnost hodnot výsledných (slovních tvarù). V ka¾dém kroku je poté ulo¾ena hodnota pravdìpodobnosti pøechodu do mo¾ných následujících stavù a hodnota pravdìpodobnosti vygenerování urèitého výstupu (znaèky). Celý proces je zachycen na obrázku ~\ref{fig:GrafHMM}.

\begin{figure}[ht!]
	\centering
		\includegraphics[width=\textwidth]{fig/HMM}
		\caption{Graf mo¾ných pøechodù a výstupù modelu}
		\label{fig:GrafHMM}
\end{figure}

Z tohoto ukázkového pøíkladu mù¾eme vyvodit, ¾e pøi posloupnosti pozorovaných tvarù ètverec, kosoètverec, kruh, trojúhelník, mù¾e \uv{skrytá} vstupní posloupnost mít jednu z podob zobrazených v tabulce ~\ref{tab:HMMPrechody}.
\begin{figure}
	\begin{center}
		\begin{tabular}{|c c c c|}
			\hline
			1 & 2 & 1 & 1 \\
			\hline
			1 & 2 & 1 & 2 \\ 
			\hline
			1 & 2 & 2 & 1 \\ 
			\hline
			1 & 2 & 2 & 3 \\
			\hline
		\end{tabular}
		\captionof{table}{Mo¾né pøechody mezi skrytými stavy modelu}
		\label{tab:HMMPrechody}
	\end{center}
\end{figure}
Nejpravdìpodobnìj¹í z nich bychom byli schopni urèit pomocí ohodnocení jednotlivých pøechodù. 

V na¹em pøípadì bychom pak pøi trénování, kdy známe jak vstupní, tak výstupní posloupnost, museli urèitým zpùsobem vypoèítat hodnoty na jednotlivých pøechodech. K tomu mù¾eme pou¾ít jeden k tomu urèených algoritmù -- Viterbiho algoritmus, Forward-Backward algoritmus, nebo Baum-Welch algoritmus. S jejich pomocí jsme poté po nìkolika iteracích schopni získat hodnoty pro ideální prùchod pøi neznámé posloupnosti.

I kdy¾ není HMM implementováno v ¾ádném z vyu¾itých programù, poskytuje základ pro pochopení algoritmu CRF.

\section{Conditional Random Fields (CRF)}
CRF mù¾eme popsat jako bezsmìrový grafický pravdìpodobnostní model (undirected probabilistic graphical model), ve kterém ka¾dý uzel (v na¹em pøípadì slovo) popisuje náhodnou promìnnou. CRF mù¾e také být vyjádøen jako model s koneèným poètem stavù a nenormalizovanými pravdìpodobnostmi pøechodù. V porovnání k HMM nemá jasnì dané hodnoty pøechodù mezi stavy a disponuje mo¾ností mnohonásobných funkcí, generujících rysy. Pøiná¹í také lep¹í výsledky ve zpracování dat se závislostmi vy¹¹ího øádu, které vìt¹inou lépe odpovídají reálnému modelu. Na rozdíl od generativních modelù také, jako¾to pravdìpodobnostní (conditional) model nemusí zkoumat v¹echny mo¾né sekvence pozorovaných prvkù (observations). Pro urèení parametrù tohoto modelu je v souèasné dobì nejvíce doporuèován algoritmus L-BFGS (Low-Memory BFGS), který poskytuje nejkvalitnìj¹í výsledky.

\subsection{Label Bias problém}
Problém ¹patného vyva¾ování znaèek (viz.\cite{Lafferty}) spoèívá v pøesunu pravdìpodobnostní hodnoty na dal¹í pozici v pøípadì pouze jediného pøechodu za ignorování pozorovaného prvku. Jak je ilustrováno na obrázku ~\ref{fig:GrafLabelBias}, v pøípadì vstupní posloupnosti písmen t,i,k se v prvním kroku neumíme rozhodnout a vstupujeme do stavù 1 a 4 se stejnou pravdìpodobností. Nyní, i kdy¾ na vstupu je písmeno i, nemáme jinou mo¾nost, ne¾ pokraèovat do stavù 2, pøípadnì 5 za ignorování pozorovaného písmena. V pøípadì, ¾e by v trénovacích datech tedy pøevládal øetìzec \uv{tik} nad øetìzcem \uv{tak}, byly by oba tyto øetìzce v¾dy urèeny jako \uv{tik}. Toto je vy¾e¹eno algoritmem CRF pomocí ohodnocení pøechodù mezi stavy, kdy mù¾eme podle aktuálního pozorovaného prvku buï sní¾it, nebo zvý¹it koneènou pravdìpodobnost dané posloupnosti.

\begin{figure}[ht!]
	\centering
		\includegraphics[width=\textwidth]{fig/LabelBias}
		\caption{Ilustrace \uv{Label Bias} prolblému}
		\label{fig:GrafLabelBias}
\end{figure}

\section{Viterbi algorithm}
Byl navrhnut v roce 1967 Andrewem Viterbi jako dekódovací algoritmus pro konvoluèní kódy v telekomunikaèních sítích. Kvùli svému zamìøení na vyhledání nejpravdìpodobnìj¹í cesty sekvencí skrytých stavù (nejèastìji HMM) se v¹ak pou¾ívá v mnoha odvìtvích, jako zpracování signálù a také znaèkování jazyka. 

Za pøedpokladu, ¾e vstupní data mají stejný poèet pozorovaných a skrytých stavù, obì posloupnosti jsou zarovnané a výpoèet v daném místì je závislý pouze na aktuálním a pøedchozím prvku, je pomocí získána tzv. Viterbiho cesta -- nejpravdìpodobnìj¹í cesta posloupností.  V ka¾dém kroku algoritmus vyhodnotí v¹echny cesty vedoucí k aktuálnímu stavu a ponechá pouze jednu, díky èemu¾ není nucen uchovávat v¹echny existující cesty, ale pouze jednu pro ka¾dý stav. Za pomocí uchovávaní ceny stavu se poka¾dé algoritmus rozhodne ze v¹ech mo¾ností pro dal¹í stav a ulo¾í kompletní cestu od zaèátku prùchodu posloupností.

\section{Forward-backward algorithm}
Pou¾ívá dva prùchody posloupností stavù -- dopøedu a zpìt (podle toho také vznikl jeho název). Nejdøíve projde celou sekvenci a urèí cenu cesty pøi daném prùchodu. Poté projde sekvencí zpìt a pøi ka¾dém kroku spoèítá pravdìpodobnost pozorování zbylých vstupních hodnot. Oba tyto prùchody jsou poté \uv{vyhlazeny} do spoleèného výsledku a tím je získáno rozdìlení mezi stavy v jednotlivých jednotkách èasu. Speciálním pøípadem je poté Baum-Welch algoritmus.
%TODO ZJISTIT VICE??

\section{L-BFGS}
L-BFGS (viz.\cite{Nash}) oznaèuje nízko pamì»ovou (Low memory) úpravu optimalizaèní metody BFGS (Broyden-Fletcher-Goldfarb-Shanno) z rodiny Quasi-Newtonových metod, urèenou k aproximaci inverzní Hessovy matice (ètvercová matice druhých parciálních derivací funkce -- popisuje místní zakøivení funkce o nìkolika promìnných). Optimalizací pro sní¾ení pamì»ové nároènosti je neukládání matice samotné, ale pouze ukládá historii zmìn.

\section{Stochastic Gradient Descent}

\section{Regularizace L1}

\section{Regularizace L2}

\chapter{Informaèní systém}
Z dùvodu velkého mno¾ství jednotlivých testù, rùzných nastavení a strojù, na kterých testování bì¾í, jsem se rozhodl vytvoøit za pomoci open-source CMS systému Drupal informaèní, který mi pomù¾e udr¾ovat si pøehled o v¹ech spu¹tìných testech a o jejich výsledcích. Systém byl vytvoøen jako modul, pou¾itelný na jakékoliv webové stránce, pou¾ívající k ulo¾ení informací databázi dané stránky (dle standardu systému Drupal). 

Systém je rozdìlen na následujících 5 èástí: 
\begin{enumerate}
	\item Spu¹tìní nového testu
	\item Dokonèení bì¾ícího testu
	\item Zobrazení bì¾ících testù
	\item Zobrazení dokonèených testù
	\item Zobrazení náhledu na v¹echny testy a jejich rysy
\end{enumerate}

\section{Návrh databáze}
Pro systém byla navr¾ena jednoduchá databáze, sestávající ze 4 tabulek a poskytující dostatek prostoru pro pøípadná roz¹íøení, o dal¹í rysy, nebo sledované výsledky.

\section{Spu¹tìní testu}
Pøi spu¹tìní se do systému zadávají následující data:
\begin{itemize}
	\item Název pou¾itého programu
	\item Identifikátor poèítaèe, na kterém testování bì¾í
	\item Popis testování
	\item Typ regularizace
	\item Poèet vstupních vìt pou¾itých pro testování
	\item Poèet vstupních vìt pou¾itých pro evaluaci
	\item Maximální poèet iterací
	\item Epsilon
	\item Pou¾ité rysy
	\item Pou¾ité èásti znaèky
\end{itemize}

\section{Dokonèení testu}
Pøi ukonèení testu se poté dodají informace, které pou¾ijeme pøi odvozování výsledkù a grafù. Mezi tyto informace patøí následující:
\begin{itemize}
	\item Poèet slov pou¾itých pøi trénování
	\item Poèet unikátních znaèek v trénovacích datech
	\item Poèet iterací
	\item Èas zaèátku a èas konce trénování
	\item Doba evaluace -- znaèkování
	\item Poèet rysù na zaèátku a na konci
	\item Velikost modelu
	\item Procentuální úspì¹nost znaèkování u jednotlivých slov a u vìt
\end{itemize}

\section{Zobrazení bì¾ících a skonèených testù, zobrazení náhledu}
Na tìchto stránkách si poté mù¾eme prohlédnout výsledky, které mù¾eme pozdìji pou¾ít k dal¹ím úèelùm. V prùbìhu testování je poté dùle¾itá stránka zobrazení náhledu, která nám zobrazuje, které testy ji¾ byly provedeny, nebo právì bì¾í, a dává nám tak jednoduchou mo¾nost rozmyslet, které testy by bylo vhodné spustit.

\chapter{Prostøedí testù}
\section{Operaèní systém}
Aèkoliv v¹echny vyu¾ívané programy a skripty jsou multiplatformní, v¹echny testy byly spou¹tìny na operaèním systému Linux nainstalovaném na univerzitních strojích, ke kterým jsem se vzdálenì pøipojoval pøes ssh. 
\section{Hardware}
Testování probíhalo prùbì¾nì a¾ na 10 rùzných poèítaèích, kde tøi znich jsou dostupné pro v¹eobecné vyu¾ítí (Athena 1 -- 3) a zbylé jsou pøístupné pouze pro výzkum zpracování jazyka (Pcnlp1 -- 8, krom 2, na kterém bì¾í OS Windows). Z dùvodu rozdílného hardware na jednotlivých strojích se poté pøi testování projevují velké skoky ve výsledných èasech. V tabulce ~\ref{tab:PouziteStroje} je zobrazena struèná charakteristika jednotlivých strojù.
%TODO Dopsat sem jejich vykon??
\begin{figure}
	\begin{center}
		\begin{tabular}{|l|l|c|}
			\hline
			\multicolumn{1}{|c|}{Název} &
			\multicolumn{1}{|c|}{CPU} & 
			\multicolumn{1}{|c|}{Velikost Pamìti} \\
			\hline
			Athena 1 & 2 x Dual-Core AMD Opteron(tm) Processor 2220 @ 2,8GHz &
			16GB \\
			Athena 2 & 2 x Dual-Core AMD Opteron(tm) Processor 2220 @ 2,8GHz &
			16GB \\
			Athena 3 & 2 x Six-Core AMD Opteron(tm) Processor 2435 @ 2,6GHz &
			64GB \\
			Pcnlp 1 & Intel(R) Core(TM)2 Quad CPU Q6700 @ 2.66GHz &
			4GB \\
			Pcnlp 3 & Intel(R) Core(TM)2 Duo CPU E6750 @ 2.66GHz &
			2GB \\
			Pcnlp 4 & Intel(R) Core(TM)2 Duo CPU E6750 @ 2.66GHz &
			2GB \\
			Pcnlp 5 & Intel(R) Core(TM)2 Duo CPU E6750 @ 2.66GHz &
			2GB \\
			Pcnlp 6 & Intel(R) Core(TM)2 Duo CPU E6750 @ 2.66GHz &
			2GB \\
			Pcnlp 7 & Intel(R) Core(TM)2 Duo CPU E8400 @ 3.00GHz &
			2GB \\
			Pcnlp 8 & Intel(R) Core(TM)2 Duo CPU E8300 @ 2.83GHz &
			2GB \\
			\hline
		\end{tabular}
		\captionof{table}{Charakteristika stroujù pou¾itých pøi zpracování projektu}
		\label{tab:PouziteStroje}
	\end{center}
\end{figure}

\chapter{CRF++}
\section{Popis programu}
Program CRF++ je open-source implementací Conditional Random Fields, urèenou pro znaèkování sekvenèních dat. Nabízí se tedy jako jeden z kandidátù pro potøeby této práce. Program je napsán v jazyce C++ za pou¾ití STL knihovny. K urèení parametru pou¾ívá algoritmu L-BFGS. Implementuje také mo¾nost bigramù -- rysù, fungujících jako pøechod mezi pøedchozím a souèasným prvkem. Tato vlastnost je v¹ak z dùvodu velkého poètu znaèek vysoce nároèná.

Nevýhodou programu je zdrojový kód bez jakýchkoliv komentáøù a tím pádem naprosto nevhodný k jakýmkoliv zásahùm, èí úpravám pro na¹e potøeby. Pøi vyu¾ití tohoto programu jsem se také potýkal s problémy s chybou SIGSEGV. Kód se zøejmì nebyl schopen vypoøádat s vysokým poètem unikátních znaèek a pøi pou¾ití v¹ech kategorii a vy¹¹ího poètu vstupù vyvolal zmínìnou vyjímku a ukonèil se.

\section{Zpùsob testování}
Pøi mo¾nosti poèítat s pøedchozím prvkem, urèeným algoritmem, se nabízí ji vyu¾ít v na¹em programu. Bohu¾el, s délkou èeské znaèky také pøichází kámen úrazu, kdy program nechápe \uv{smysl} pøedchozí znaèky, ale bere ji jako celek (z dùvodu optimalizací je øetìzec pøeveden na èíslo, se kterým jsou poté v¹echny operace mnohem rychlej¹í). Nemù¾e tedy vyu¾ít jednotlivých èástí èeské znaèky k vytvoøení samostatných pravidel. Tím se sni¾ují mo¾nosti zpracování a efektivity pou¾itých algoritmù, stejnì jako generování rysù. Pøi pokusech o vyøe¹ení tohoto problému jsem vytvoøil skript, který postupnì zpracovává èásti znaèky a poté je pou¾ívá pøi trénování dal¹ích krokù. Tento pøístup je v¹ak velmi krkolomný a celkovì nepøinesl markantní nárùst úspì¹nosti.

\section{Znaèkování textu}
V pøípadì tohoto programu se pravidla na tvorbu rysù pøedávají jako konfiguraèní soubor a proto je nutné v¹echny pøedbì¾né úpravy udìlat u¾ na vstupních datech. K tomuto úèelu byl vytvoøen skript v jazyce awk, který je poté volán z hlavního skriptu, starajícího se o celý prùbìh trénování. 

Nastavení v konfiguraèním souboru jsou poté tvoøena písmenem, urèujícím, zda jde o unigram (vztahujícíc se pouze k souèasnému prvku posloupnosti), èi o bigram (vý¹e zmínìný pøechod mezi pøedchozím a aktuálním prvkem). Poté následuje dvouciferný identifikátor rysu, zajis»ující unikátnost vùèi ostatním definicím, dvojteèkou a øetìzcem definujícím pou¾itá vstupní data. K tomu je vyu¾íván zápis \%[x,y], kde x oznaèuje relativní pozici mezi slovy (0 oznaèuje aktuální, záporné èíslo pøedchozí a kladné následující prvek) a y oznaèuje sloupec vstupních dat, který má být pou¾it. Celé pravidlo poté mù¾e vypadat napø. takto: U01:\%[0,1].

Jeliko¾ znaèkování probíhá v nìkolika krocích, kdy v ka¾dém z nich nám pøibude dal¹í sloupec a dal¹í souvislosti mezi daty, je nutno pøipravit pro ka¾dý krok samostatný konfiguraèní soubor. Také je dùle¾ité správnì jej nastavit pro co nejlep¹í výslednou úspì¹nost.

Pro øízení procesu byl sepsán skript v jazyce BASH, který vyu¾ívá programu pro tvorbu vstupních dat, napsaného v jazyce C, pøevádìjícího øetìzce na èísla, a dal¹ího skriptu v jazyce awk urèeného ke koneèné analýze úspì¹nosti.

\section{Pou¾ité rysy}
Z dùvodu nìkolika-krokového charakteru testování se rysy velmi li¹í, veskrze jde v¹ak pouze o kombinace pøedchozích a aktuálních prvkù vstupních souborù. Také byly pou¾ity nìkolikanásobné rysy, skládající se zároveò ze dvou prvkù (minulá a souèasná znaèka apod.). Pro tyto pravidla mi povìt¹inou byly inspirací existující konfiguraèní soubory pou¾ívané pro trénování anglického jazyka, které byly souèástí pøíkladù pou¾itých v programu CRF++. Pro tvoøení rysù bylo pou¾ito: Tvar slova, Lemmata (slo¾enina v¹ech mo¾ných lemmat), èást znaèky, urèující slovní druh (pokud se shodovala ve v¹ech mo¾nostech vstupních dat) a prùbì¾nì získaných výsledkù.

\section{Rozdìlení zpracování na kroky}
Správné rozdìlení bylo testováno, motivací v¹ak bylo nejdøíve natrénovat nejdùle¾itìj¹í èásti znaèky a pokraèovat s ménì významnými sloupci. Pøi tomto testování se tedy bude moci ji¾ pou¾ít natrénovaných dat k lep¹ím výsledkùm. V prvním kroku proto bylo èasto pou¾ito slovního druhu a jeho detailu, v druhém rodu, osoby, pádu a ve tøetím nìkolika ze zbylých vlastností. 

\section{Výsledky testování}
Testù bylo vykonáno nìkolik desítek, vìt¹ina z nich v¹ak nepøiná¹ela ký¾ené výsledky. V tabulce ~\ref{tab:CRFVysledky} proto zahrnuji pouze vzorek dat s uspokojivými výsledky.

\begin{figure}
	\begin{center}
		\begin{tabular}{|c|r|r|c|c|r|r|}
			\hline
			\multicolumn{1}{|c|}{Id testu} &
			\multicolumn{1}{|c|}{Poèet vìt} & 
			\multicolumn{1}{|c|}{Eta} &
			\multicolumn{1}{|c|}{Krok è.} &
			\multicolumn{1}{|c|}{Èásti znaèky} &
			\multicolumn{1}{|c|}{Poèet pøíznakù} &
			\multicolumn{1}{|c|}{Úspì¹nost} \\
			\hline
			1 & 3000 & 0.05  & 1 & 1100000000000000 & 1318350 & 94.099\% \\
			  &      &       & 2 & 0010100100000000 & 2354463 & 59.105\% \\
			  &      &       & 3 & 0001000010000000 & 299812  & 80.526\% \\
			\hline
			2 & 3000 & 0.005 & 1 & 1100000000000000 & 2065745 & 92.487\% \\
		 	  &      &       & 2 & 0010100100000000 & 1716750 & 75.100\% \\
			  &      &       & 3 & 0001000110000000 & 897138  & 87.055\% \\ 
			\hline
			2 & 5000 & 0.005 & 1 & 1100000000000000 & 1318350 & 94.312\% \\
			  &      &       & 2 & 0010100000000000 & 1097024 & 71.303\% \\
			  &      &       & 3 & 0001000110000000	& 596079  & 84.856\% \\
			\hline
		\end{tabular}
		\captionof{table}{Výsledky testování pøi vyu¾ití programu CRF++}
		\label{tab:CRFVysledky}
	\end{center}
\end{figure}

\section{Odklon od programu}
Ze v¹ech vý¹e zmínìných dùvodù (padání programu, nekomentovaného kódu, \ldots) a také po zkoumání dal¹ích existujících øe¹ení, o kterých jejich autoøi tvrdí, ¾e jejich díla jsou øádovì rychlej¹í, ne¾ CRF++, jsem se rozhodl tento program opustit a tím pádem jsem ze získaných dat nevyvodil ¾ádné závìry, nebo» by v koneèném dùsledku byly pouze zbyteènou prací, nemající vliv na závìreèný výsledek celé práce.



\chapter{Závìr}

%=========================================================================
